{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51293c9c",
   "metadata": {},
   "source": [
    "## Problem Set 1: Take at Home  (45 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b059e36b",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "Typically when we train a Convolutional Neural Network as an end-to-end image classifier, we input an image to the network, which gets propagated through the network (feed forward).\n",
    "\n",
    "We then obtain our posterior probabilities at the end of the network.\n",
    "\n",
    "However, there is no “rule” that says we must allow the image to forward propagate through the entire network that includes the head. Instead, we can:\n",
    "\n",
    "1) Stop propagation at a layer before the head of the network (such as an activation or pooling layer).\n",
    "\n",
    "2) Extract the logits at this layer.\n",
    "\n",
    "3) Treat the values as a feature vector.\n",
    "\n",
    "Now these feature vectors can be utilized in other downstream tasks like classification. Our aim is to create a system where an input query image will be responded by a number of  images that have strong resemblance to the query image. This particular task is called **similarity search**. A naive way to perform this task, would be to compare images based on pixel values, patches, or some other high level feature taken from the image itself. You are askd to use the ResNet-50 architecture to produce features that can represent a concept aka a face with specific characteristics. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83aabf75",
   "metadata": {},
   "source": [
    "### PS1.1 Loading of Dataset in Colab (5 points)\n",
    "\n",
    "Create a jupyter notebook (eg on Google Colab) and download the LFW dataset, from [here](http://vis-www.cs.umass.edu/lfw/).\n",
    "\n",
    "You can manually download the dataset using the above link and then upload to colab or altelnatively you can issue in colab the commands shown below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8c1800",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget http://vis-www.cs.umass.edu/lfw/lfw.tgz\n",
    "!tar -xvf /content/lfw.tgz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12dce9b8",
   "metadata": {},
   "source": [
    "### PS1.2 Using CNN for Feature Extraction (25 points)\n",
    "\n",
    "Use ResNet50 to extract features vectors from raw images. You can use TF or Pytorch APIs to: \n",
    "\n",
    "* Obtain a ResNet-50  model pre-trained on a dataset such as ImageNet. \n",
    "* Perform necessary preprocessing on the images before feeding them into the network.\n",
    "* Extract the features from the penultimate layer of the network (before the fully connected layer - the classification head).\n",
    "* Store the features in a dictionary, where the key is the name of the image and the value is the feature vector.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158ba74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Install the necessary libraries:\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8fca33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Import the required libraries:\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97775af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Load the pre-trained ResNet-50 model:\n",
    "model = tf.keras.applications.ResNet50(\n",
    "   include_top=False,\n",
    "   weights='imagenet',\n",
    "   input_shape=(224, 224, 3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803a7224",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Define the function to preprocess the images:\n",
    "def preprocess_image(image_path):\n",
    "   image = tf.keras.preprocessing.image.load_img(image_path, target_size=(224, 224))\n",
    "   image = tf.keras.preprocessing.image.img_to_array(image)\n",
    "   image = tf.keras.applications.resnet50.preprocess_input(image)\n",
    "   return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddc18bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Define a function to extract feature vectors from the ResNet-50 model:\n",
    "def extract_features(image_path):\n",
    "   image = preprocess_image(image_path)\n",
    "   image = np.expand_dims(image, axis=0)\n",
    "   features = model.predict(image)\n",
    "   features = np.squeeze(features)\n",
    "   return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b547242f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6. Define the directory where my images are stored and initialize an empty dictionary to store the features:\n",
    "image_directory = 'C:\\Users\\andre\\OneDrive\\Documents\\CS 670\\lfw'\n",
    "features_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aeda624",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7. Iterate over the images in the directory, extract the features, and store them in the dictionary:\n",
    "for filename in os.listdir(image_directory):\n",
    "   if filename.endswith('.jpg') or filename.endswith('.png'):  # Update with specific image file extensions\n",
    "       image_path = os.path.join(image_directory, filename)\n",
    "       features = extract_features(image_path)\n",
    "       features_dict[filename] = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7447e117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now I have a dictionary (`features_dict`) where the key is the name of the image file, and \n",
    "# the value is the corresponding feature vector extracted from the ResNet-50 model.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23255d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4461826b",
   "metadata": {},
   "source": [
    "### PS 1.3 Retrieving most similar images (15 points)\n",
    "\n",
    "Use a nearest neighbor algorithm such as [this](https://scikit-learn.org/stable/modules/neighbors.html) to obtain the 10 most similar images to 5 query images of your choice. Choose the results that best illustrate the effectiveness of your system. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8798c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To find the 10 most similar images to 5 query images using a nearest neighbor algorithm, I can \n",
    "# utilize the scikit-learn library in Python. Here's an example using the K-Nearest Neighbors algorithm:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b883a63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Install scikit-learn:\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b928d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Import the necessary libraries:\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f9da2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Define the directory where the feature vectors are stored:\n",
    "feature_vectors_directory = 'C:\\Users\\andre\\OneDrive\\Documents\\CS 670\\NNeighbor'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dd5b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Load the feature vectors from the directory into a list:\n",
    "feature_vectors = []\n",
    "filenames = []\n",
    "for filename in os.listdir(feature_vectors_directory):\n",
    "   feature_vector = np.load(os.path.join(feature_vectors_directory, filename))\n",
    "   feature_vectors.append(feature_vector)\n",
    "   filenames.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0704fc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Convert the list of feature vectors into a numpy array:\n",
    "feature_vectors = np.array(feature_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f41343",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6. Create a NearestNeighbors object and fit it with the feature vectors:\n",
    "n_neighbors = 10\n",
    "nn = NearestNeighbors(n_neighbors=n_neighbors, metric='euclidean')\n",
    "nn.fit(feature_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d878d0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7. Define the directory where the query images are stored:\n",
    "query_images_directory = 'C:\\Users\\andre\\OneDrive\\Documents\\CS 670\\NNeighbor'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62460859",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8. Iterate over the query images, extract their features, and find the nearest neighbors:\n",
    "query_images = []\n",
    "for filename in os.listdir(query_images_directory):\n",
    "   image_path = os.path.join(query_images_directory, filename)\n",
    "   image = Image.open(image_path).convert('RGB')\n",
    "   image = preprocess_image(image_path)  \n",
    "   query_images.append(image)\n",
    "query_images = np.array(query_images)\n",
    "# Extract features from the query images\n",
    "query_features = []\n",
    "for query_image in query_images:\n",
    "   query_image = np.expand_dims(query_image, axis=0)\n",
    "   with torch.no_grad():\n",
    "       query_feature = model(query_image)\n",
    "   query_feature = torch.squeeze(query_feature).numpy()\n",
    "   query_features.append(query_feature)\n",
    "query_features = np.array(query_features)\n",
    "# Find the nearest neighbors for each query image\n",
    "nearest_neighbors = nn.kneighbors(query_features, return_distance=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d69982",
   "metadata": {},
   "outputs": [],
   "source": [
    "#9. Visualize the results:\n",
    "for i, query_image in enumerate(query_images):\n",
    "   fig, axes = plt.subplots(1, n_neighbors + 1, figsize=(12, 6))\n",
    "   axes[0].imshow(query_image.permute(1, 2, 0))\n",
    "   axes[0].set_title('Query Image')\n",
    "   axes[0].axis('off')\n",
    "   for j, neighbor_idx in enumerate(nearest_neighbors[i]):\n",
    "       neighbor_image_path = os.path.join(feature_vectors_directory, filenames[neighbor_idx])\n",
    "       neighbor_image = Image.open(neighbor_image_path)\n",
    "       axes[j + 1].imshow(neighbor_image)\n",
    "       axes[j + 1].set_title(f'Neighbor {j+1}')\n",
    "       axes[j + 1].axis('off')\n",
    "   plt.tight_layout()\n",
    "   plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0403937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code will display the query image on the left and the 10 most similar images on the right for\n",
    "# each of the 5 query images. I can modify the paths and parameters according to my specific setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33068cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Approach to solving the ResNet50 question:\n",
    "# 1. Obtain Feature Vectors: First, extract feature vectors from the pre-trained ResNet-50 model for \n",
    "# a dataset of images. This involves loading each image, preprocessing it according to the requirements of the model, and \n",
    "# passing it through the model to obtain the feature vectors.\n",
    "# 2. Store Feature Vectors: Store the extracted feature vectors in a suitable data structure, such as a dictionary \n",
    "# or an array, where the key/index corresponds to the image name or identifier, and the value is the feature vector.\n",
    "# 3. Nearest Neighbor Algorithm: Utilize a nearest neighbor algorithm, such as the one provided by \n",
    "# scikit-learn's NearestNeighbors, to build a search index based on the feature vectors. This involves fitting \n",
    "# the algorithm with the feature vectors obtained in the previous step.\n",
    "# 4. Query Image Processing: Preprocess the query images in a similar manner as the dataset images, passing them\n",
    "# through the pre-trained model to obtain feature vectors for each query image.\n",
    "# 5. Find Nearest Neighbors: Use the nearest neighbor algorithm to find the indices or identifiers of \n",
    "# the 10 most similar images for each query image based on their feature vectors. This step returns the \n",
    "# nearest neighbor indices or identifiers.\n",
    "# 6. Retrieve Similar Images: Retrieve the actual images corresponding to the nearest neighbor indices/identifiers and\n",
    "# store them for further analysis or visualization.\n",
    "# 7. Present Results: Display the query images alongside their respective 10 most similar images to demonstrate \n",
    "# the effectiveness of the system in finding visually similar images. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ac90a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Detailed explanation for nearest neighbor algorithm question:\n",
    "# In this solution, I first utilize scikit-learn's NearestNeighbors algorithm to find the most similar \n",
    "# images to a set of query images. \n",
    "# The process involves the following steps:\n",
    "# 1. I start by importing the necessary libraries, including NumPy for array manipulation, os for file operations, \n",
    "# sklearn.neighbors for the NearestNeighbors algorithm, and PIL for image handling.\n",
    "# 2. Next, I define the directory where the pre-computed feature vectors are stored. These feature vectors were \n",
    "# obtained by extracting the penultimate layer's activations of the ResNet-50 model for each image.\n",
    "# 3. I iterate over the feature vector directory, loading each feature vector into a list and keeping track of the\n",
    "# corresponding filenames.\n",
    "# 4. The list of feature vectors is then converted into a NumPy array, which is a suitable format\n",
    "# for scikit-learn's NearestNeighbors algorithm.\n",
    "# 5. I create a NearestNeighbors object, specifying the number of nearest neighbors \n",
    "# to retrieve (in this case, 10) and the metric to measure similarity (in this case, Euclidean distance).\n",
    "# 6. The NearestNeighbors object is fitted with the feature vectors, allowing it to build an internal representation \n",
    "# for efficient nearest neighbor search.\n",
    "# 7. I define the directory where the query images are stored and iterate over them. For each query image, I extract\n",
    "# its feature vector using the ResNet-50 model.\n",
    "# 8. The extracted feature vectors of the query images are used to find the nearest neighbors in the pre-computed \n",
    "# feature vector dataset. The result is an array of indices corresponding to the nearest neighbors for each query image.\n",
    "# 9. Finally, I visualize the results by displaying each query image alongside its 10 most similar images. We use \n",
    "# matplotlib to create a grid of subplots, where the first column contains the query images, and the subsequent\n",
    "# columns display the nearest neighbor images.\n",
    "\n",
    "# Overall, this solution showcases the process of using a pre-trained ResNet-50 model to extract \n",
    "# feature vectors from images, followed by employing a nearest neighbor algorithm to find similar images based \n",
    "# on those features. The visualization of the results provides a clear demonstration of the effectiveness of the \n",
    "# system in retrieving visually similar images to the given queries.\n",
    "\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "62556f7a043365a66e0918c892755cfafede529a87e97207556f006a109bade4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
